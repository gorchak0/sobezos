/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.26. Консенсус",
  "answer": "Консенсус — это механизм, позволяющий узлам распределённой системы договориться об общем состоянии или решении, даже если часть узлов вышла из строя или сеть работает с задержками. Он критически важен для согласованности данных в кластерах БД, распределённых файловых системах и сервисах координации.\nКлючевые свойства:\n- **Атомарность:** решение либо принимается всеми, либо никем.\n- **Согласованность:** все участники приходят к одному и тому же результату.\n- **Устойчивость:** принятое решение сохраняется и после сбоев или перезапуска.\n- **Толерантность к сбоям:** консенсус должен достигаться, даже если часть узлов работает некорректно.\nКлассический алгоритм — **Paxos**, но он довольно сложен для практической реализации. Поэтому чаще применяют **Raft** (например, в etcd, Consul) или **Zab** (в ZooKeeper), которые проще для понимания и внедрения.\nНа практике консенсус нужен для:\n- согласованной репликации данных,\n- выбора лидера в кластере,\n- обеспечения корректной работы распределённых транзакций.\nБез механизма консенсуса в распределённой системе мы можем получить split-brain или разные узлы будут видеть разные состояния данных."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.27. Дебаг медленных запросов.",
  "answer": "Дебаг медленных запросов — это комбинация анализа плана выполнения, проверки индексов и мониторинга нагрузки. Обычно я действую так:\n1. **Сначала план выполнения.** В PostgreSQL это `EXPLAIN`/`EXPLAIN ANALYZE`. Смотрю, где узкие места: Seq Scan вместо Index Scan, дорогие JOIN’ы, сортировки без индексов.\n2. **Логирование.** Включаю `log_min_duration_statement`, чтобы понять, какие запросы реально тормозят в проде.\n3. **Анализ в контексте приложения.** Проверяю, нет ли N+1 запросов со стороны ORM или избыточных SELECT’ов. Иногда проблема не в БД, а в коде.\n4. **Индексы.** Оптимизирую: добавляю недостающие, убираю лишние, смотрю на селективность. Если индекс не помогает — возможно, данные слишком перекошены.\n5. **Архитектурные шаги.** Если проблема в больших объёмах данных — партиционирование, денормализация, кэширование (Redis, Materialized Views).\n6. **Конфигурация БД.** Иногда достаточно подстроить work_mem, shared_buffers или parallel workers.\n7. **Мониторинг.** Смотрю статистику из `pg_stat_statements`, чтобы видеть частоту и среднее время выполнения запросов.\nВ итоге стратегия простая: сначала находишь «бутылочное горлышко» через EXPLAIN/логи, потом решаешь, что оптимизировать — запрос, индексы, схему или саму конфигурацию БД."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.28. Логическое партиционирование.",
  "answer": "Логическое партиционирование — это способ разбить большую таблицу на несколько частей (партиций) по какому-то критерию: например, по дате, диапазону значений, категории или региону. В итоге мы работаем не с гигантской таблицей целиком, а только с нужным кусочком данных.\nКлючевые плюсы:\n- **Производительность.** Запросы быстрее, потому что они обращаются только к нужной партиции, а не ко всей таблице.\n- **Управляемость.** Проще оперировать данными — можно удалять/архивировать целые партиции, а не миллионы строк.\n- **Обслуживание.** Индексы, вакуум, оптимизация — всё это можно делать отдельно для каждой партиции.\n- **Масштабируемость.** Добавление новых партиций позволяет безболезненно растить систему.\n- **Гибкость.** Можно распределять партиции по разным серверам или даже использовать для разграничения доступа.\nПростой пример: есть таблица логов за много лет. Вместо одной огромной таблицы можно завести партиции по месяцам или годам. Тогда свежие запросы будут ходить только в актуальные данные, а старые партиции можно архивировать или перенести на дешёвое хранилище."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.29. Как можно оценить работу кэша? Что можно кэшировать?",
  "answer": "Оценка работы кэша обычно строится на метриках. Ключевые показатели:\n- **Объём памяти под кэш** — базовый ресурсный показатель.\n- **RPS чтения/записи.** В норме чтений должно быть в разы больше, чем записей. Если наоборот — кэш работает неэффективно.\n- **Количество элементов в кэше** — помогает отлавливать слишком большие записи.\n- **Hit rate.** Самый главный показатель: насколько часто данные берутся из кэша, а не из источника.\n- **Expired rate.** Процент записей, удалённых из\\-за истечения TTL. Если он высок — возможно, TTL выставлен неправильно.\n- **Eviction rate.** Процент вытеснений из\\-за нехватки памяти. Важно для выбора стратегии вытеснения (LRU, LFU и т.д.).\nЧто кэшировать:\n- **Часто изменяющиеся данные** (секунды/минуты) почти не имеет смысла кэшировать, разве что ошибки или специфичные кейсы.\n- **Нечасто изменяющиеся данные** (минуты/часы/дни) — основной кандидат. Примеры: списки товаров, их описания, агрегированные данные.\n- **Редко изменяющиеся данные** (недели/годы) можно смело кэшировать, но всегда выставлять TTL — нет данных, которые не меняются «никогда».\nНа практике я обычно начинаю с анализа паттернов запросов: что чаще всего читается и насколько данные стабильны. Дальше настраиваю метрики, слежу за hit rate и eviction rate — и уже по ним оптимизирую стратегию."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.30. Планировщик запросов в postgresql. Explain и explain analyse.",
  "answer": "В PostgreSQL планировщик запросов — это компонент, который выбирает оптимальный способ выполнения SQL-запроса. Его задача — среди множества возможных планов (например, сканирование по индексу или полный проход по таблице, разный порядок JOIN’ов, методы сортировки) выбрать тот, который будет дешевле всего по оценочной «стоимости» с учётом статистики данных.\nОсновные шаги работы планировщика:\n1. **Анализ SQL.** Определяет, какие таблицы, столбцы, фильтры и соединения участвуют.\n2. **Генерация планов.** Строит несколько возможных стратегий выполнения.\n3. **Оценка стоимости.** Использует статистику (селективность, кардинальность, размеры таблиц/индексов).\n4. **Выбор плана.** Берёт наименее затратный и отдаёт его на исполнение.\n5. **Выполнение.** Запрос идёт по выбранному пути, но PostgreSQL может динамически корректировать поведение (например, для `LIMIT`).\nТеперь про инструменты:\n**EXPLAIN** — показывает план выполнения без фактического запуска. Полезно, когда хочешь понять, как запрос будет исполняться, и проверить, будет ли использован индекс.\n`EXPLAIN SELECT * FROM customers WHERE age \u003e 30;`\n**EXPLAIN ANALYZE** — реально выполняет запрос и даёт статистику: время по каждому шагу, количество обработанных строк, где были отклонения от прогнозов планировщика.\n`EXPLAIN ANALYZE SELECT * FROM customers WHERE age \u003e 30;`\nНа практике я обычно начинаю с `EXPLAIN`, чтобы понять план, а если хочу проверить реальную производительность и узкие места — использую `EXPLAIN ANALYZE`. В связке они позволяют оптимизировать запросы и понять, почему СУБД выбрала тот или иной путь."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.31. Что такое deadlock в PostgreSQL?",
  "answer": "Deadlock \\- это ситуация, при которой два или более процесса заблокированы, потому что каждый из них ждет ресурс, который удерживает другой процесс.\nPostgreSQL обнаруживает ситуации deadlock и предпринимает попытки разрешить их автоматически. Это может включать в себя прерывание одной из блокирующих транзакций, чтобы разблокировать другую. Однако автоматическое разрешение deadlock может потребовать отката части транзакции, что может повлиять на целостность данных, поэтому это следует учитывать при проектировании базы данных и приложений."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.32. Как можно обнаружить deadlock в PostgreSQL?",
  "answer": "Deadlock возникает, когда две или более транзакции блокируют ресурсы и ждут друг друга, из\\-за чего ни одна не может продолжить выполнение. В PostgreSQL есть несколько способов обнаружить и диагностировать такие ситуации:\n1. **Автоматическое обнаружение:** PostgreSQL сам детектирует deadlock и прерывает одну из транзакций, выдавая ошибку `ERROR: deadlock detected`. В логи пишется подробная информация о транзакциях и заблокированных ресурсах.\n2. **Логирование долгих ожиданий:** можно включить параметры `log_lock_waits = on` и `deadlock_timeout`, чтобы фиксировать ситуации, когда транзакции ждут блокировку слишком долго.\n**Системные представления:** в современных версиях PostgreSQL поле `waiting` устарело. Вместо этого используют `wait_event_type` и `wait_event` в `pg_stat_activity`, чтобы увидеть все транзакции, которые ожидают ресурсы:\n`SELECT pid, usename, query, state, wait_event_type, wait_event`\n`FROM pg_stat_activity`\n`WHERE state = 'active' AND wait_event IS NOT NULL;`\n3.  Этот запрос показывает потенциальные блокировки. Важно понимать, что не каждое ожидание — это deadlock, но такие данные помогают локализовать проблемные транзакции.\n4.  **Анализ блокировок вручную:** можно использовать `pg_locks` совместно с `pg_stat_activity`, чтобы увидеть, какие транзакции держат и ждут блокировки. Это полезно для построения графа зависимостей и выявления циклов, ведущих к deadlock.\n5.  **EXPLAIN и профилирование транзакций:** иногда deadlock вызван определённым порядком операций над таблицами. Анализ порядка доступа к ресурсам и профилирование запросов помогают предотвратить повторение.\n**Итог:** стратегия диагностики — мониторинг длительных блокировок через `pg_stat_activity` и `pg_locks`, логирование долгих ожиданий, анализ ошибок deadlock в логах и корректировка порядка транзакций."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.33. Что такое многоверсионность в PostgreSQL?",
  "answer": "Многоверсионность в PostgreSQL — это механизм, который позволяет одновременно читать и изменять данные без блокировок. Она критически важна для обеспечения высокой конкурентности и целостности данных, особенно в системах с большим количеством параллельных транзакций.\nPostgreSQL использует концепцию **MVCC (Multi-Version Concurrency Control)**. Каждая транзакция видит свой собственный «снимок» данных, и изменения одной транзакции не мешают другой до момента фиксации (commit).\nОсновные моменты, которые стоит понимать:\n1. **Снимки данных (Snapshots)**\n- Каждая транзакция работает с версией данных на момент её старта.\n- Это позволяет параллельно выполнять чтение и запись без блокировки строк, что сильно повышает производительность.\n2. **MVCC**\n- Каждая строка в таблице хранит метаданные о времени создания и удаления.\n- Когда транзакция делает запрос, она видит только «живые» строки, актуальные на момент её старта.\n3. **Изоляция транзакций**\n- MVCC обеспечивает высокий уровень изоляции: каждая транзакция видит свой собственный снимок данных.\n- Это предотвращает «грязное» чтение и позволяет безопасно параллелить операции.\n4. **Одновременные чтение и запись**\n- Благодаря многоверсионности PostgreSQL может обрабатывать множество операций чтения и записи одновременно.\n- Это критично для сервисов с высокой нагрузкой и большим количеством пользователей.\n5. **Работа с большими объемами данных**\n- MVCC и снимки позволяют эффективно масштабировать систему и сохранять производительность даже при интенсивной многозадачности.\n6. **ACID**\n- Многоверсионность помогает PostgreSQL полностью поддерживать ACID-транзакции: атомарность, согласованность, изоляцию и долговечность."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.34. Что такое WAL в PostgreSQL?",
  "answer": "WAL — это **журнал предзаписи**, который фиксирует все изменения данных **до того, как они попадут в основную базу**. Проще говоря, это механизм безопасности и восстановления: если система падает или происходит сбой, PostgreSQL использует WAL для восстановления данных до последнего согласованного состояния.\nКлючевые моменты:\n1. **Предотвращение потери данных**\n- Все изменения сначала записываются в WAL, затем в основную таблицу.\n- Даже если база не успела записать изменения на диск, WAL гарантирует, что они не потеряются.\n2. **Восстановление после сбоя**\n- При рестарте PostgreSQL читает WAL и воспроизводит все изменения, которые ещё не были применены к основным файлам данных.\n3. **Производительность**\n- WAL позволяет PostgreSQL выполнять операции записи эффективнее, так как журнал последовательный, а не случайный, что снижает накладные расходы на I/O.\n4. **Репликация и резервное копирование**\n- WAL активно используется для потоковой репликации и создания резервных копий, обеспечивая консистентное состояние базы на разных серверах."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "7.35. Как ускорить работу с базой данных",
  "answer": "**Индексация**\n- Создавайте индексы на колонках, которые участвуют в фильтрах, join’ах и сортировках.\n- Индексы позволяют базе данных быстро находить нужные записи без полного сканирования таблицы.\n**Оптимизация SQL-запросов**\n- Пересмотрите запросы: уменьшайте количество отдельных вызовов, выбирайте более эффективные операторы и используйте подзапросы там, где это оправдано.\n**Кэширование**\n- Кэшируйте результаты часто выполняемых запросов в памяти (например, Redis или Memcached).\n- Это снижает нагрузку на базу и ускоряет повторный доступ к данным.\n**Масштабирование**\n- **Вертикальное** — увеличивайте ресурсы существующего сервера.\n- **Горизонтальное** — добавляйте дополнительные узлы для распределения нагрузки.\n**Индексированные представления**\n- Если есть часто используемые сложные запросы, создавайте материализованные или индексированные представления.\n**Ограничение объема данных**\n- Удаляйте устаревшие записи и архивируйте редко используемые данные.\n- Меньший объем данных ускоряет выполнение запросов.\n**Оптимизация сетевых запросов**\n- Снижайте количество и объем запросов между клиентом и сервером.\n- Используйте батчинг и lazy-загрузку там, где это возможно.\n**Использование NoSQL для специфичных задач**\n- Для сценариев с низкой структурированностью данных NoSQL может дать существенный прирост скорости.\n**Мониторинг и профилирование**\n- Используйте инструменты мониторинга, чтобы выявлять медленные запросы и узкие места.\n- Это помогает принимать целенаправленные решения по оптимизации."
}
