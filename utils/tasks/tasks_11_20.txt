/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.2. Что такое CAP?",
  "answer": "CAP — это аббревиатура, которая означает Consistency, Availability, Partition tolerance (Согласованность, Доступность, Устойчивость к разделению). Это свойства распределенных систем.\n\n- Согласованность (Consistency) — это свойство распределенной системы, которое гарантирует, что каждый узел системы видит одни и те же данные одновременно.\n\n- Доступность (Availability) — это свойство распределенной системы, которое гарантирует, что каждый запрос к системе будет завершен успешно.\n\n- Устойчивость к разделению (Partition tolerance) — это свойство распределенной системы, которое гарантирует, что система будет работать даже в случае разделения сети на части."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.3 Что такое транзакция?",
  "answer": "Транзакция — это набор операций, которые выполняются как единое целое. Транзакции используются для обеспечения целостности данных в реляционных базах данных."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.4 Паттерны транзакций",
  "answer": "Существует несколько паттернов транзакций, которые описывают распространенные способы использования и управления транзакциями. Вот некоторые из них:\n\n1. **Транзакция с сохранной точкой (Savepoint Transaction)**\n\nИспользуется, когда внутри одной транзакции есть несколько шагов, и не все из них критичны.\n\nМы можем поставить savepoint и при ошибке откатиться только до него, не отменяя всю работу. Это особенно полезно, когда транзакция длинная и не хочется терять всё прогресс.\n\n2. **Gather-insert Transaction**\n\nЭто паттерн для сценариев высокой конкуренции на вставку.\n\nВместо того чтобы держать блокировки на одной таблице и ловить конфликты, данные сначала пишутся в буферные (временные) таблицы. Потом в транзакции они объединяются.\n\nЗа счёт этого снижается уровень блокировок и улучшается масштабируемость.\n\n3. **Пессимистическая блокировка (Pessimistic Locking)**\n\nКлассический вариант, когда мы сразу ставим блокировку на строку или ресурс.\n\nХорошо работает, когда вероятность конфликта высокая и цена отката велика.\n\nНо у такого подхода есть минус — блокировки могут держаться долго, создавая задержки для других транзакций.\n\n4. **Оптимистическая блокировка (Optimistic Locking)**\n\nПротивоположный подход: блокировок нет, вместо этого используется версионирование (например, поле `version` или timestamp).\n\nПеред записью проверяем, не изменились ли данные. Если изменились — транзакцию нужно повторить.\n\nОтлично подходит для сценариев, где конфликты редки, а нагрузка высокая.\n\n5. **Распределенная транзакция (Distributed Transaction)**\n\nЗдесь речь про работу с несколькими источниками данных или сервисами. Обычно применяется протокол двухфазного коммита **(2PC) или саги**. Это сложная история, потому что растет латентность и появляется много точек отказа..\n\n6. **Компенсирующая транзакция (Compensating Transaction)**\n\nЧасто используется в распределенных системах вместо жёсткого ACID. Если один из шагов в цепочке не удался, то мы не делаем откат, а выполняем “обратную” транзакцию, которая логически компенсирует ошибку. Это как раз основа паттерна **Saga** в микросервисах."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.5 Что такое 2pc",
  "answer": "**Two-Phase Commit (2PC)**\n\nЭто классический протокол для распределённых транзакций. Его задача — гарантировать атомарность, когда одна транзакция затрагивает несколько ресурсов (например, базы данных на разных серверах).\n\nМеханизм работает в два шага:\n\n1. **Prepare (фаза голосования):** координатор рассылает запрос всем участникам: “Можешь ли ты зафиксировать транзакцию?”. Каждый участник резервирует ресурсы и отвечает “готов” или “отмена”.\n\n2. **Commit/Rollback (фаза фиксации):** если все ответили “готов” — координатор посылает “commit”. Если хоть один сказал “отмена” — всем рассылается “rollback”.\n\n**Плюсы:** гарантирует согласованность.\n\n**Минусы:** синхронность и блокировки → участники ждут решения координатора, возможна ситуация “зависшей транзакции” при сбое. Поэтому 2PC плохо масштабируется и редко используется в микросервисах в чистом виде."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.6 Что такое saga",
  "answer": "**Saga**\n\nЭто более современный паттерн для распределённых систем, в частности для микросервисов. В отличие от 2PC, саги не делают жёсткий глобальный commit/rollback, а строятся как последовательность локальных транзакций, каждая из которых выполняется в своём сервисе.\n\n- Если все шаги успешны — считаем, что вся сага прошла успешно.\n\n- Если один из шагов падает — запускаются **компенсирующие транзакции** для отката предыдущих шагов.\n\n**Реализация бывает двух видов:**\n\n- **Хореография (choreography):** шаги саги запускаются событиями. Один сервис завершил транзакцию → публикует событие → следующий сервис реагирует.\n\n- **Оркестрация (orchestration):** есть центральный “оркестратор”, который управляет выполнением шагов и вызывает нужные сервисы.\n\n**Плюсы:** асинхронность, отказоустойчивость, подходит для микросервисов.\n\n**Минусы:** сложнее в реализации, нужны компенсирующие транзакции и продуманная архитектура (особенно в хореографии может получиться “messy event hell”).\n\n##"
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.7 Когда использовать 2pc а когда saga",
  "answer": "Используем **2PC**, когда:\n\n- критична строгая атомарность (ACID),\n\n- ресурсов немного и они под нашим полным контролем,\n\n- допустимы блокировки и задержки (например, внутри одного кластера БД).\n\nИспользуем **Saga**, когда:\n\n- система распределённая (микросервисы),\n\n- нужна масштабируемость и отказоустойчивость,\n\n- можем жить с eventual consistency и реализовать компенсирующие транзакции.\n\n**Реальный кейс как пример:**\n\n- **Сервис A (Задачи)** → хранит и выдаёт пользователю задания.\n\n- **Сервис B (Ответы)** → хранит правильные ответы.\n\n- У каждого своя база.\n\nТеперь допустим, у нас есть операция:\n\n“**Создать новую задачу вместе с правильным ответом**”.\n\nТут задействованы **оба сервиса** → получается распределённая транзакция.\n\n**Пример сценария (хореография)**\n\n1. Сервис A (Задачи) создаёт задачу → публикует событие `TaskCreated`.\n\n2. Сервис B (Ответы) подписан на `TaskCreated` → создаёт правильный ответ → публикует событие `AnswerCreated`.\n\n3. Если создание ответа упало → сервис B публикует событие `AnswerCreationFailed`.\n\n4. Сервис A подписан на `AnswerCreationFailed` → выполняет компенсирующую транзакцию (удаляет задачу).\n\nПлюсы хореографии\n\n- Нет централизованного компонента → меньше узких мест.\n\n- Сервисы более независимые.\n\n- Хорошо масштабируется при большом количестве микросервисов.\n\n🔹 Минусы\n\n- Сложнее отлаживать → события могут приходить в разном поряде.\n\n- Нужно аккуратно продумывать все компенсации.\n\n- Возможны ситуации “messy event hell”, если много шагов и много сервисов.\n\n“**Messy Event Hell**” — это неофициальный термин, который описывает хаос, возникающий в системах, построенных на **событиях**, особенно в хореографических сагaх.\n\n**Пример сценария (оркестратор):**\n\n1. Сервис A → “создать задачу” (локальная транзакция в его БД).\n\n2. Сервис B → “создать правильный ответ” (локальная транзакция в его БД).\n\n3. Если шаг 2 упал → оркестратор вызывает у сервиса A операцию “откатить задачу” (например, удалить созданную задачу).\n\n| ![][image1] | Каждый сервис сам отвечает за свою БД (никаких общих транзакций). У каждого сервиса есть API для компенсации (например, `DELETE /tasks/:id` или `DELETE /answers/:id`). Оркестратор (может быть отдельным сервисом или даже одна функция в Go) выполняет шаги один за другим и вызывает компенсации при ошибке. |\n\n| :---------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n\n| ![][image2] | В итоге у тебя нет строгой атомарности, как в 2PC, но система приходит к консистентному состоянию: либо задача и ответ оба есть, либо оба удалены.                                                                                                                                                              |"
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.8. Подходы к управлению транзакциями",
  "answer": "**1\\. Локальные транзакции**\n\n**(Local Transactions)**\n\n- **Описание:** применяются к одной базе данных или ресурсу. Всё происходит внутри одной СУБД, и транзакции управляются средствами самой базы.\n\n- **Пример:** обычные SQL-транзакции (`BEGIN`, `COMMIT`, `ROLLBACK`) внутри Postgres или MySQL.\n\n**Когда использовать:** если система монолитная и весь функционал ограничен одной базой — это самый простой и безопасный вариант.\n\n**2\\. Распределенные транзакции**\n\n**(Distributed Transactions)**\n\n- **Описание:** затрагивают несколько баз данных или ресурсов, часто на разных серверах. Применяются протоколы вроде **2PC**, чтобы обеспечить атомарность.\n\n- **Пример:** перевод денег между счетами в разных банках, где каждая база должна согласованно обновить свои данные.\n\n**Когда использовать:** критически важно соблюсти **ACID** на нескольких ресурсах, но протоколы тяжёлые, блокировки могут тормозить систему.\n\nВ микросервисах 2PC используют редко.\n\n**3\\. Управление транзакциями на уровне приложения**\n\n**(Application-Level Transaction Management)**\n\n- **Описание:** приложение самостоятельно начинает, фиксирует и откатывает транзакции через API СУБД или сервисов.\n\n- **Пример:** в Go через `db.Begin()` → `tx.Commit()` / `tx.Rollback()`.\n\n**Когда использовать:** если нужна гибкость и контроль над поведением транзакции в коде, например для комбинирования нескольких шагов внутри одного сервиса.\n\n**4\\. Управление транзакциями на уровне объекта**\n\n**(Object-Level Transaction Management)**\n\n- **Описание:** транзакции управляются на уровне объектов или моделей данных. Каждый объект может иметь свою транзакцию, возможны вложенные транзакции.\n\n- **Пример:** ORM с поддержкой транзакций (GORM, Hibernate), где можно оборачивать операции с объектами в транзакцию.\n\n**Когда использовать:** удобно при работе с объектно-ориентированными системами или при сложной бизнес-логике, где разные объекты должны обновляться атомарно.\n\n**5\\. Управление транзакциями на уровне сообщений**\n\n**(Message-Level Transaction Management)**\n\n- **Описание:** транзакции управляются через сообщения в асинхронных системах. Каждое сообщение может быть частью транзакции, поддерживаются атомарные операции с очередью.\n\n- **Пример:** Kafka или RabbitMQ с транзакциями, когда публикация и обработка сообщений должны быть согласованы с изменениями данных.\n\n**Когда использовать:** в распределённых или event-driven системах, когда нет возможности или желания держать глобальные блокировки, а важна согласованность через события.\n\n**Итог:**\n\nВыбор подхода зависит от архитектуры:\n\n- **Монолит, одна БД** → локальные транзакции.\n\n- **Микросервисы, распределённые ресурсы** → saga или message-level транзакции.\n\n- **Классическая банковская система** → можно 2PC, но с оглядкой на блокировки и отказоустойчивость."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.9. Уровни изоляции транзакций",
  "answer": "**Уровни изоляции транзакций** определяют, какие изменения данных видны другим транзакциям во время выполнения текущей транзакции.\n\n**Read Uncommitted (Чтение неподтвержденных данных)**\n\nТранзакция может видеть **неподтвержденные изменения**, внесённые другими транзакциями. Возможны “грязные” чтения.\n\n**Read Committed (Чтение подтвержденных данных)**\n\nТранзакция видит только **подтвержденные изменения** других транзакций. Грязные чтения исключены, но возможны неповторяемые чтения (non-repeatable reads).\n\n**Repeatable Read (Повторяемое чтение)**\n\nТранзакция **гарантированно видит одни и те же данные при повторном чтении** в рамках своей транзакции. Возможны фантомные записи (новые строки, вставленные другими транзакциями, могут появиться).\n\n**Serializable (Сериализуемость)**\n\nТранзакции выполняются так, как будто они **выполняются последовательно**. Исключены грязные чтения, неповторяемые чтения и фантомные записи.\n\n**Snapshot (Снимок, характерен для PostgreSQL и некоторых СУБД)**\n\nТранзакция работает с **снимком данных на момент её начала**. Все изменения, внесённые другими транзакциями после начала, не видны. Поведение похоже на Repeatable Read, но с гарантией изоляции через версионирование данных (MVCC).\n\n\\*Неповторяемое чтение (Non-Repeatable Read) транзакция читает одни и те же строки дважды, и между этими чтениями другая транзакция изменила эти данные.\n\n\\*Грязное чтение (Dirty Read) транзакция читает данные, которые были изменены другой транзакцией, но ещё не подтверждены (не committed)."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.10. Что такое in-memory хранилище? Какие есть решения? Зачем они нужны?",
  "answer": "**In-memory хранилище (In-memory storage)**\n\n- **Определение:** Хранение данных в оперативной памяти (RAM) вместо HDD/SSD.\n\n- **Главное преимущество:** Очень быстрый доступ к данным → высокая производительность и низкая задержка.\n\n**Популярные решения:**\n\n- **Redis:** Кэш, очередь сообщений, in-memory база данных. Поддерживает строки, списки, множества, хэши.\n\n- **Memcached:** Простой кэш данных в памяти для ускорения доступа (HTML, изображения).\n\n- **Apache Cassandra:** Распределённая база данных, использует RAM для кэша, высокая доступность и масштабируемость.\n\n- **VoltDB:** Реляционная in-memory база для транзакций в реальном времени.\n\n- **Hazelcast:** Распределённое in-memory хранилище, кэширование и распределённые вычисления.\n\n**Зачем нужны:**\n\n1. **Высокая производительность** – чтение/запись быстрее диска.\n\n2. **Снижение задержки** – критично для финансовых приложений, игр, real-time систем.\n\n3. **Масштабируемость** – легко масштабируются горизонтально."
}
/taskadd
{
  "tags": [
    "мод_4_БД"
  ],
  "question": "2.11. Какие есть подходы к масштабированию?",
  "answer": "Масштабирование — это способ повысить производительность и устойчивость системы при росте нагрузки.\n\n**Вертикальное масштабирование (Vertical scaling)**\n\n- Увеличение мощности одного сервера: больше CPU, RAM, диска.\n\n- Просто в реализации, но ограничено пределами «железа» и дорого при больших масштабах.\n\n**Горизонтальное масштабирование (Horizontal scaling)**\n\n- Добавление новых серверов/инстансов в кластер.\n\n- Позволяет распределять нагрузку и повышать отказоустойчивость.\n\n- Основной подход в современных высоконагруженных системах.\n\n**Облачное масштабирование (Cloud scaling)**\n\n- Автоматическое увеличение/уменьшение ресурсов (auto-scaling) в AWS, GCP, Azure.\n\n- Удобно для переменной нагрузки (например, пики в e-commerce).\n\n**Микросервисы**\n\n- Разделение системы на независимые сервисы.\n\n- Масштабируем только «узкие места», а не всё приложение целиком.\n\n- Легче внедрять гибкое горизонтальное масштабирование.\n\n**Балансировка нагрузки (Load balancing)**\n\n- Равномерное распределение запросов между инстансами.\n\n- Увеличивает производительность и даёт отказоустойчивость.\n\n**Кэширование (Caching)**\n\n- Снижение нагрузки на БД и сервисы за счёт сохранения часто используемых данных.\n\n- Используется на разных уровнях: CDN, Redis/Memcached, кэш на уровне приложения.\n\n**Шардинг (Sharding)**\n\n- Разделение данных на сегменты (шарды) и хранение их на разных серверах.\n\n- Позволяет работать с огромными объёмами данных.\n\n**Оптимизация кода и запросов**\n\n- Перед масштабированием железа часто стоит оптимизировать приложение: пересмотреть SQL-запросы, убрать «бутылочные горлышки».\n\n- Иногда грамотная оптимизация даёт больший прирост, чем добавление серверов."
}
